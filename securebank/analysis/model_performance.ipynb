{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import json  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\shrin\\OneDrive\\Documents\\GitHub\\babel-shrinit\\securebank')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrin\\OneDrive\\Documents\\GitHub\\babel-shrinit\\securebank\\modules\\raw_data_handler.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data['is_fraud'].fillna(0, inplace=True)  # Fill missing fraud labels with 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: ../storage/dataset/final_data.parquet\n"
     ]
    }
   ],
   "source": [
    "from modules.raw_data_handler import Raw_Data_Handler\n",
    "import os\n",
    "handler = Raw_Data_Handler()\n",
    "\n",
    "# file paths\n",
    "customer_file = '../data_sources/customer_release.csv'\n",
    "transaction_file = '../data_sources/transactions_release.parquet'\n",
    "fraud_file = '../data_sources/fraud_release.json'\n",
    "\n",
    "customer_data, transaction_data, fraud_data = handler.extract(customer_file, transaction_file, fraud_file)\n",
    "\n",
    "# transform data\n",
    "final_data = handler.transform(customer_data, transaction_data, fraud_data)\n",
    "\n",
    "final_data_path = '../storage/dataset/final_data.parquet'\n",
    "handler.load(final_data, final_data_path)\n",
    "\n",
    "\n",
    "print(f\"Cleaned data saved to: {final_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ../storage/dataset/train_data.parquet\n",
      "Dataset saved to ../storage/dataset/test_data.parquet\n",
      "Training and testing datasets saved.\n"
     ]
    }
   ],
   "source": [
    "from modules.dataset_design import Dataset_Designer\n",
    "\n",
    "dataset_designer = Dataset_Designer()\n",
    "\n",
    "final_data = dataset_designer.extract('../storage/dataset/final_data.parquet')\n",
    "\n",
    "# training and testing split\n",
    "train_data, test_data = dataset_designer.sample(final_data)\n",
    "\n",
    "dataset_designer.load([train_data, test_data], ['../storage/dataset/train_data.parquet', '../storage/dataset/test_data.parquet'])\n",
    "\n",
    "print(\"Training and testing datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.feature_extractor import Feature_Extractor\n",
    "\n",
    "feature_extractor = Feature_Extractor()\n",
    "\n",
    "\n",
    "train_data, test_data = feature_extractor.extract('../storage/dataset/train_data.parquet', '../storage/dataset/test_data.parquet')\n",
    "\n",
    "train_features, test_features = feature_extractor.transform(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Model saved to: c:\\Users\\shrin\\OneDrive\\Documents\\GitHub\\babel-shrinit\\securebank\\storage\\models\\artifacts\\logistic_regression.pkl\n",
      "Training Naive Bayes...\n",
      "Model saved to: c:\\Users\\shrin\\OneDrive\\Documents\\GitHub\\babel-shrinit\\securebank\\storage\\models\\artifacts\\naive_bayes.pkl\n",
      "Performance metrics saved to: c:\\Users\\shrin\\OneDrive\\Documents\\GitHub\\babel-shrinit\\securebank\\storage\\models\\artifacts\\model_performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from modules.feature_extractor import Feature_Extractor\n",
    "\n",
    "base_dataset_path = os.path.abspath('../storage/dataset')\n",
    "base_model_path = os.path.abspath('../storage/models/artifacts')\n",
    "\n",
    "os.makedirs(base_model_path, exist_ok=True)\n",
    "\n",
    "train_data_path = os.path.join(base_dataset_path, 'train_data.parquet')\n",
    "test_data_path = os.path.join(base_dataset_path, 'test_data.parquet')\n",
    "\n",
    "\n",
    "(train_features, train_labels), (test_features, test_labels) = feature_extractor.transform(\n",
    "    pd.read_parquet(train_data_path),\n",
    "    pd.read_parquet(test_data_path)\n",
    ")\n",
    "# convert to array\n",
    "train_features = train_features.toarray()\n",
    "test_features = test_features.toarray()\n",
    "\n",
    "# models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "performance_metrics = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(train_features, train_labels)\n",
    "    y_pred = model.predict(test_features)\n",
    "    y_prob = model.predict_proba(test_features)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(test_labels, y_pred),\n",
    "        'Precision': precision_score(test_labels, y_pred),\n",
    "        'Recall': recall_score(test_labels, y_pred),\n",
    "        'F1 Score': f1_score(test_labels, y_pred),\n",
    "        'AUC': roc_auc_score(test_labels, y_prob) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "    performance_metrics[model_name] = metrics\n",
    "\n",
    "    model_filename = f\"{model_name.replace(' ', '_').lower()}.pkl\"\n",
    "    model_path = os.path.join(base_model_path, model_filename)\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "metrics_df = pd.DataFrame(performance_metrics).T\n",
    "metrics_filename = os.path.join(base_model_path, 'model_performance_metrics.csv')\n",
    "metrics_df.to_csv(metrics_filename)\n",
    "print(f\"Performance metrics saved to: {metrics_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
